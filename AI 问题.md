# RAG（Retrieval-Augmented Generation）：
---
**没有 RAG 的 LLM**：像一个只读了固定教材（训练数据）的学生，进行“闭卷考试”。他知识渊博，但知识截止于某个时间点，且可能会记错或编造（幻觉）。
**有 RAG 的 LLM**：同一个学生，但现在他可以带参考资料（外部知识库）进场“开卷考试”。当被问到一个问题时，他会先去参考资料里查找最相关的部分，然后结合查到的信息和自己的理解来给出答案。

### 工作流程
	1.Query接收问题
- Retrieval检索：系统不会直接把问题扔给 LLM。而是将问题转换为一个向量查询，去一个专门的**知识库（通常是向量数据库，如 Pinecone, Chroma, Weaviate 等）**中进行搜索。这个知识库预先存储了大量关于苹果产品、新闻稿、评测等信息的文本块，并已转换成向量形式。

- Augmented增强：系统会找到与问题最相关的几个文本块（例如，关于 Vision Pro 功能介绍的几段原文）。然后，将这些检索到的文本块作为**上下文信息**，与用户的原始问题**合并**成一个新的、更丰富的提示 (Prompt)。

- 生成：将这个增强后的 Prompt 发送给 LLM。LLM 会基于提供的上下文信息来生成一个准确、详细且有事实依据的答案，从而大大减少了“幻觉”现象。

- 特点：扩展知识范围、提高准确性。

- 应用：问答系统、智能客服、搜索引擎等。

一、RAG相关Query处理阶段的优化

Query 改写与扩写 具体实现：

1. 规则改写：同义词替换、模板添加、正则匹配(如，日期标准化)。

2. 大模型生成：利用 GPT 改写、扩展句子。灵活自然但可能冗余。

3. 意图识别：NLU提取意图，重组 Query。查天气，自动给三天内天气。

4. 多样化生成：提供多个改写候选项。如，天气 ，是一天后还是一周后

5. 历史反馈优化：结合用户数据或历史记录，靠高频(如，用户男爱运动，则买鞋变为买男士运动鞋)或RLHF改进。好处是更贴近用户习惯，坏处是隐私泄露。

RAG Pipeline各个流程以及具体优化方向

1) 用户输入Query查询：输入Query后支持改扩。具体优化目标：查询语义清晰简单以精准检索用户实际需求

2) 检索知识库出相关信息：构建(高质量数据并向量化、高效索引的)向量知识库；向量检索(FAISS/Weaviate)或关键词检索(BM25)；循环多轮应用扩改Query检索以确保无遗漏；过滤低相关；冗余或低置信度结果。具体优化目标：知识库无噪声、检索效率高、结果相关性高。

3) 结果预处理：去不相关以内容精简；按相关性排序；文图表音多模态转化统一。具体优化目标：确保检索结果适合生成模型输入限制。

4)生成阶段：拼接检索以及上下文增强；用RLHF后领域大模型；生成多候选答案好筛选；剔除逻辑不通或不准的答案。具体优化目标：生成质量高，逻辑清晰，提升多样性的答案。

5) 输出与反馈：提供多样化答案供用户选择，标明参考来源和置信度，收集用户反馈，更新知识库使其具备时效性和准确度。具体优化目标：提用户满意度和可信度。

6) 性能优化：缓存中间结果、分布式部署检索和生成模块提升并发能力、批量化模型优化(剪枝/量化/蒸馏)。具体优化目标：降模型延迟、提吞吐能力。
---
### RAG 改写扩写如何实现？

这是 RAG 和 Agent 结合的绝佳范例。Agent 负责“决策”，RAG 作为其可以使用的“工具”之一。

**实现流程：**

假设 Agent 的任务是：“请将这段关于‘量子计算’的简介扩写成一篇 500 字的科普文章，要求内容准确且通俗易懂。”

1. **意图识别与规划 (Agent)**：
    
    - Agent 首先理解任务是“扩写”，主题是“量子计算”，要求是“准确”和“通俗易懂”。
    - Agent 制定计划：
        1. “我需要更多关于量子计算的基础知识、最新进展和有趣的比喻。”
        2. “我将使用 RAG 工具来检索这些信息。”
        3. “获取信息后，我将结合原始简介和新信息，生成一篇新的文章。”
        4. “最后，我会检查文章是否满足 500 字和通俗易懂的要求。”
2. **执行检索 (Agent 使用 RAG 工具)**：
    
    - Agent 根据规划，自动生成几个用于 RAG 的查询，例如：
        - `"量子计算的基本原理是什么？"`
        - `"量子比特和传统比特的区别"`
        - `"量子计算在现实生活中的潜在应用"`
        - `"解释量子叠加和量子纠缠的通俗比喻"`
    - RAG 系统执行这些查询，从知识库中返回最相关的文本片段。
3. **整合与生成 (Agent + LLM)**：
    
    - Agent 将**原始简介** + **RAG 检索到的所有信息** + **最终指令**整合到一个最终的 Prompt 中。
    - 这个 Prompt 大致会是这样：`“请你扮演一位科普作家。使用以下背景知识：[插入RAG检索到的所有资料...]，将这段文字：[插入原始简介...]，扩写成一篇约500字的、关于量子计算的科普文章。文章需要确保事实准确，并使用简单的比喻，让非专业人士也能理解。”`
    - LLM 根据这个极其丰富和明确的 Prompt 生成最终的文章。

通过这个流程，Agent 利用 RAG 获取了高质量的“原材料”，从而出色地完成了改写和扩写的任务。
# Agent
---
如果说 RAG 是让 LLM “会查资料”，那么 Agent 就是让 LLM **“会思考、会行动”**。一个 AI Agent 是一个能够自主理解目标、制定计划、并使用工具去完成任务的系统。

**一个典型的 Agent 核心组件：**

1. **感知 (Perception)**：接收和理解环境信息，主要是用户的指令，但也可能包括来自其他系统或工具的反馈。
2. **规划 (Planning)**：Agent 的“大脑”。这是核心部分，它会将一个宏大的目标（如：“帮我预订下周五去上海的机票和酒店”）分解成一系列可执行的步骤。这个过程本身就可能需要 LLM 的多次“思考”。常用的规划模式有 **ReAct (Reason + Act)**，即“思考”下一步该做什么，然后“行动”（使用工具）。
3. **记忆 (Memory)**：
    - **短期记忆**：用于在一次任务中保持上下文连贯。
    - **长期记忆**：将过去的经验、成功和失败的策略存储起来，用于未来的决策，通常也需要借助向量数据库。
4. **工具使用 (Tool Use)**：Agent 的“手和脚”。Agent 本身不能订机票或查天气，但它可以**调用外部的 API 或函数**来完成这些事。例如，它可以调用 `search_flight()` API、`book_hotel()` API、计算器、代码解释器或进行网络搜索。


### 多 Agent 协同如何实现？

多 Agent 协同模仿了人类团队的工作模式，让不同的 Agent 扮演不同角色，共同完成一个复杂任务。

**实现模式主要有以下几种：**

1. **层级式 (Hierarchical)**：像一个公司，有一个“经理”Agent 和几个“员工”Agent。
    
    - **流程**：用户向“经理”Agent 提出一个复杂任务（如：“分析一下特斯拉最近的财报，并生成一份市场前景预测报告”）。
    - **经理 Agent** 负责分解任务，将子任务分配给专门的“员工”，例如：
        - **研究员 Agent**：负责上网搜索和下载特斯拉最新财报（使用搜索工具）。
        - **数据分析师 Agent**：负责从财报中提取关键数据并进行分析（使用代码解释器或数据分析API）。
        - **报告撰写员 Agent**：负责将前两个 Agent 的结果汇总，撰写成最终报告。
    - “经理”Agent 监督整个流程，并将最终结果整合后呈现给用户。**AutoGen** 就是这种模式的典型代表。
2. **协作式 / 辩论式 (Collaborative / Debate)**：所有 Agent 地位平等，像一个圆桌会议。
    
    - **流程**：一个 Agent 提出一个想法或方案，其他 Agent 对其进行评估、批评、补充或提出替代方案。这个过程不断迭代，直到达成共识或生成一个最优解。
    - **应用**：非常适合需要创意、代码生成与审查、或复杂问题解决的场景。例如，一个 Agent 写代码，另一个 Agent 负责测试和 Debug。**ChatDev** 项目就模拟了软件开发公司的协作流程。

**协同实现的关键技术**：

- **共享状态/记忆 (Shared State/Memory)**：需要一个所有 Agent 都能访问的“白板”或数据库，来同步任务进度、共享文件和中间结果。
- **通信协议 (Communication Protocol)**：Agent 之间需要一套明确的沟通规则，谁先说，谁后说，如何传递结果。
- **角色定义 (Role Prompting)**：通过精心设计的 Prompt，为每个 Agent 分配清晰的角色、职责和能力。

---

### 五、除了 Agent，还有其他自主决策的 AI 架构吗？

是的。Agent 架构是目前在 LLM 时代最流行的一种范式，但自主决策的理念源远流长。

1. **强化学习 (Reinforcement Learning, RL)**：这是最经典的自主决策框架。一个智能体 (Agent) 在一个环境 (Environment) 中不断尝试，通过获得奖励 (Reward) 或惩罚 (Punishment) 来学习最优策略 (Policy)。AlphaGo 就是一个著名的例子。现代 LLM Agent 有时也会用 RL 来微调其决策模型，使其更擅长使用工具。
    
2. **分层任务网络 (Hierarchical Task Networks, HTN)**：一种经典的 AI 规划技术。它不是从零开始思考，而是将任务分解为预先定义好的、更小的子任务和方法。它比 LLM Agent 更结构化、更可靠，但灵活性较差。适用于流程固定的场景（如游戏 NPC 的行为逻辑）。
    
3. **行为树 (Behavior Trees)**：在游戏和机器人领域非常流行。它通过一个树状结构来组织决策逻辑（顺序、选择、并行等），使得复杂的行为可以被模块化和清晰地设计出来。它提供了一种比有限状态机更灵活的决策方式。
    

**混合架构**：目前最前沿的系统往往是混合架构。例如，一个 Agent 的顶层规划可能由 LLM 负责（灵活性），而底层的具体执行步骤可能由更稳定的行为树或 HTN 来控制（可靠性）。

---

### 目前市面上非常好的 Agent 架构是哪些？

这里的“架构”更多指的是实现 Agent 的**框架和模式**。

1. **LangChain**：最著名、最全面的 LLM 应用开发框架。它不是一个单一的 Agent，而是提供了构建 Agent 所需的**全套工具箱**，包括模型封装、Prompt 管理、记忆模块、工具接口、以及 Agent 执行器（如 ReAct 模式的 Agent）。几乎是所有开发者入门 Agent 的首选。
    
2. **AutoGen (Microsoft Research)**：专为**多 Agent 协同**设计的框架。其核心理念是通过“对话”让多个可配置的 Agent 协同工作。它的 `UserProxyAgent`（用户代理）和 `AssistantAgent`（助理代理）模型非常强大，可以轻松构建“经理-员工”或“程序员-测试员”这样的协作模式。
    
3. **CrewAI**：一个新兴且非常受欢迎的多 Agent 框架。它专注于**角色扮演**和**协作流程**，设计理念非常清晰。你只需要定义几个 Agent 的角色（Role）、目标（Goal）和背景故事（Backstory），然后定义一个任务流程（Process），CrewAI 就能让它们像一个真正的团队一样协同工作。它比 AutoGen 更易于上手。
    
4. **ReAct (Reason + Act) 模式**：这本身不是一个框架，而是一个被广泛采用的**核心设计模式**。由谷歌提出，几乎所有现代 Agent 框架（如 LangChain）都内置了对 ReAct 的支持。它的“思考 -> 行动 -> 观察 -> 再思考”循环是单 Agent 实现自主规划的基础。


